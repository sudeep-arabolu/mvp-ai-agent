# AIâ€¯Analyticsâ€¯AgentÂ (MVP)

> Conversational assistant that lets programâ€‘management teams ask plainâ€‘English questions and receive **SQLâ€‘grade numbers _plus_ narrative context** in real time.

---

## ğŸŒ  Project Overview
Traditional BI dashboards show numbers but hide the â€œwhy.â€  
This MVP fuses **warehouse accuracy** with **LLM reasoning**:

* Exact KPIs (budget, velocity, MTTRâ€¦) come straight from Aurora queries.  
* Explanations are enriched with risk descriptions, milestone text, OKRsâ€”retrieved semantically from pgvector embeddings.  
* A single endpoint streams answers tokenâ€‘byâ€‘token to the UI, producing a ChatGPTâ€‘like experience without sacrificing data fidelity.

---

## âœ¨  Key Features

| Feature | Benefit |
|---------|---------|
| **Hybrid Retrieval (SQLÂ +Â Vector)** | Numbers never hallucinate; narrative answers stay relevant. |
| **Streaming Serverâ€‘Sent Events** | Users see answers materialise in <â€¯1â€¯s, boosting perceived speed. |
| **No Ops for MVP** | Runs locally or in one ECSâ€¯Fargate task; hourly Lambda keeps embeddings fresh. |
| **Cloudâ€‘native Security** | All data stays inside AWS; IAM + SecretsÂ Manager, no external keys. |

---

## ğŸ¯  System Design Goals

| Goal | Design Choice |
|------|---------------|
| **Accuracy first** | Route numeric questions to SQL, not the LLM. |
| **Explainability** | Attach the text snippet/source behind every answer. |
| **Costâ€‘efficiency** | pgvector inside Aurora until >â€¯3â€¯M vectors, then OpenSearch. |
| **Incremental growth** | LangChain tools let us bolt on Jira, GitHub, SAP via config, not code rewrites. |
| **Fast POC â†’ easy prod** | Same FastAPI code runs on laptop, Lambda, or Fargate. |

---

## ğŸ–¼ï¸  Architecture

```mermaid
flowchart TD
    subgraph Browser
        FE["React UI<br/>(useChat hook)"]
        FE -- "POST /ask<br/>(SSE)" --> APIGW["APIÂ Gateway*"]
    end

    subgraph Backend
        APIGW --> AGENT["FastAPI<br/>Hybrid Agent"]
        AGENT -- "SQL" --> DB[(Aurora<br/>Starâ€‘Schema)]
        AGENT -- "kâ€‘NN" --> VEC[(pgvector<br/>Embeddings)]
        AGENT --> LLM["Bedrock<br/>ClaudeÂ 3Â Haiku"]
    end

    VEC --- EMBED[[Bedrock<br/>CohereÂ v3Â Large]]

    subgraph Jobs
        EMBJOB["smart_embed.py<br/>Hourly Lambda"]
        DB -.-> EMBJOB
        EMBJOB -.-> VEC
    end
